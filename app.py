# app.py â€” NeuroEarly Pro (final): advanced EEG preprocessing + improved questionnaire + bilingual PDF (EN + AR)
import io
import os
import json
import math
import tempfile
import urllib.request
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import mne

# ReportLab for PDF
from reportlab.platypus import (
    SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image as RLImage
)
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont

# Optional Arabic shaping
try:
    import arabic_reshaper
    from bidi.algorithm import get_display
    ARABIC_SUPPORT = True
except Exception:
    ARABIC_SUPPORT = False

# ---------- Config ----------
st.set_page_config(page_title="NeuroEarly Pro", layout="wide")
st.sidebar.title("NeuroEarly Pro")
st.sidebar.info("Research demo â€” not a clinical diagnosis")

LANG_UI = st.sidebar.selectbox("Interface language / Ù„ØºØ© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])
IS_EN = LANG_UI == "English"

# ---------- Texts ----------
TEXT = {
    "English": {
        "title": "ğŸ§  NeuroEarly Pro â€” EEG Screening (Demo)",
        "subtitle": "Advanced preprocessing, PHQ-9, AD8 and professional bilingual PDF report (research only).",
        "upload": "1) Upload EDF file(s)",
        "upload_hint": "Upload a single EDF for one session or multiple EDF files for longitudinal trend.",
        "phq": "PHQ-9 (Depression)",
        "ad8": "AD8 (Cognitive screening)",
        "generate": "Generate Reports (JSON / CSV / PDF)",
        "note": "Research demo. Not a clinical diagnostic tool."
    },
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "title": "ğŸ§  Ù†ÙŠÙˆØ±ÙˆØ¥ÙŠØ±Ù„ÙŠ Ø¨Ø±Ùˆ â€” ÙØ­Øµ EEG (Ù†Ù…ÙˆØ°Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠ)",
        "subtitle": "Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©ØŒ PHQ-9ØŒ AD8 ÙˆØªÙ‚Ø±ÙŠØ± PDF Ø§Ø­ØªØ±Ø§ÙÙŠ Ø«Ù†Ø§Ø¦ÙŠ Ø§Ù„Ù„ØºØ© (Ù„Ù„Ø¨Ø­Ø« ÙÙ‚Ø·).",
        "upload": "Ù¡) ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª EDF",
        "upload_hint": "Ø§Ø±ÙØ¹ Ù…Ù„Ù EDF ÙˆØ§Ø­Ø¯ Ù„Ù„Ø¬Ù„Ø³Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ø£Ùˆ Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª Ù„ØªØ­Ù„ÙŠÙ„ Ø·ÙˆÙ„ÙŠ.",
        "phq": "PHQ-9 (Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨)",
        "ad8": "AD8 (Ø§Ù„ÙØ­Øµ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ)",
        "generate": "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± (JSON / CSV / PDF)",
        "note": "Ù‡Ø°Ø§ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø­Ø«ÙŠ. Ù„ÙŠØ³ ØªØ´Ø®ÙŠØµÙ‹Ø§ Ø·Ø¨ÙŠÙ‹Ø§."
    }
}
TUI = TEXT["English"] if IS_EN else TEXT["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"]

# ---------- Questionnaire text bilingual (we'll use these both in UI and in PDF) ----------
PHQ_QS = {
    "English": [
        "Little interest or pleasure in doing things",
        "Feeling down, depressed, or hopeless",
        "Trouble falling or staying asleep, or sleeping too much",
        "Feeling tired or having little energy",
        "Poor appetite or overeating (specify type below)",
        "Feeling bad about yourself â€” or that you are a failure",
        "Trouble concentrating on things (e.g., reading, TV)",
        "Moving or speaking slowly vs. being restless (choose best)",
        "Thoughts that you would be better off dead or of hurting yourself"
    ],
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": [
        "Ù‚Ù„Ø© Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø£Ùˆ Ø§Ù„Ù…ØªØ¹Ø© ÙÙŠ Ø§Ù„Ù‚ÙŠØ§Ù… Ø¨Ø§Ù„Ø£Ù†Ø´Ø·Ø©",
        "Ø§Ù„Ø´Ø¹ÙˆØ± Ø¨Ø§Ù„Ø­Ø²Ù† Ø£Ùˆ Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨ Ø£Ùˆ Ø§Ù„ÙŠØ£Ø³",
        "Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„Ù†ÙˆÙ… Ø£Ùˆ Ø§Ù„Ù†ÙˆÙ… Ø§Ù„Ù…ÙØ±Ø·",
        "Ø§Ù„Ø´Ø¹ÙˆØ± Ø¨Ø§Ù„ØªØ¹Ø¨ Ø£Ùˆ Ù‚Ù„Ø© Ø§Ù„Ø·Ø§Ù‚Ø©",
        "ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø´Ù‡ÙŠØ© Ø£Ùˆ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„Ø£ÙƒÙ„ (Ø­Ø¯Ø¯ Ø§Ù„Ù†ÙˆØ¹ Ø£Ø¯Ù†Ø§Ù‡)",
        "Ø§Ù„Ø´Ø¹ÙˆØ± Ø¨Ø£Ù†Ùƒ Ø´Ø®Øµ Ø³ÙŠØ¡ Ø£Ùˆ ÙØ§Ø´Ù„",
        "ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ØªØ±ÙƒÙŠØ² (Ù…Ø«Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø£Ùˆ Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ØªÙ„ÙØ§Ø²)",
        "Ø¨Ø·Ø¡ ÙÙŠ Ø§Ù„Ø­Ø±ÙƒØ© Ø£Ùˆ Ø§Ù„ÙƒÙ„Ø§Ù… Ù…Ù‚Ø§Ø¨Ù„ ÙØ±Ø· Ø§Ù„Ù†Ø´Ø§Ø· (Ø§Ø®ØªØ± Ø§Ù„Ø£Ù†Ø³Ø¨)",
        "Ø£ÙÙƒØ§Ø± Ø¨Ø£Ù†Ùƒ Ø£ÙØ¶Ù„ Ø­Ø§Ù„Ø§Ù‹ Ù…ÙŠØªØ§Ù‹ Ø£Ùˆ Ø£ÙÙƒØ§Ø± Ø¥ÙŠØ°Ø§Ø¡ Ø§Ù„Ù†ÙØ³"
    ]
}
PHQ_OPTS = {
    "English": ["0 = Not at all", "1 = Several days", "2 = More than half the days", "3 = Nearly every day"],
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": ["0 = Ø£Ø¨Ø¯Ø§Ù‹", "1 = Ø¹Ø¯Ø© Ø£ÙŠØ§Ù…", "2 = Ø£ÙƒØ«Ø± Ù…Ù† Ù†ØµÙ Ø§Ù„Ø£ÙŠØ§Ù…", "3 = ÙƒÙ„ ÙŠÙˆÙ… ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹"]
}
SPECIAL_Q8 = {
    "English": [
        "0 = Neither slow nor restless",
        "1 = Mostly calm/slow",
        "2 = Mostly restless",
        "3 = Both slow and restless"
    ],
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": [
        "0 = Ù„Ø§ Ø¨Ø·ÙŠØ¡ ÙˆÙ„Ø§ Ù…ÙØ±Ø· Ø§Ù„Ø­Ø±ÙƒØ©",
        "1 = ØºØ§Ù„Ø¨Ø§Ù‹ Ù‡Ø§Ø¯Ø¦ / Ø¨Ø·ÙŠØ¡",
        "2 = ØºØ§Ù„Ø¨Ø§Ù‹ Ù…ÙØ±Ø· Ø§Ù„Ù†Ø´Ø§Ø·",
        "3 = ÙƒÙ„Ø§Ù‡Ù…Ø§ Ø¨ÙˆØ¶ÙˆØ­"
    ]
}

AD8_QS = {
    "English": [
        "Problems with judgment (e.g., bad financial decisions)",
        "Reduced interest in hobbies/activities",
        "Repeats the same questions or stories",
        "Trouble learning to use a tool or gadget",
        "Forgets the correct month or year",
        "Difficulty handling finances (e.g., paying bills)",
        "Trouble remembering appointments",
        "Everyday thinking is getting worse"
    ],
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": [
        "Ù…Ø´Ø§ÙƒÙ„ ÙÙŠ Ø§Ù„Ø­ÙƒÙ… Ø£Ùˆ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª",
        "Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø§Ù‡ØªÙ…Ø§Ù… Ø¨Ø§Ù„Ù‡ÙˆØ§ÙŠØ§Øª Ø£Ùˆ Ø§Ù„Ø£Ù†Ø´Ø·Ø©",
        "ØªÙƒØ±Ø§Ø± Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø£Ùˆ Ø§Ù„Ù‚ØµØµ",
        "ØµØ¹ÙˆØ¨Ø© ÙÙŠ ØªØ¹Ù„Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯Ø§Ø© Ø£Ùˆ Ø¬Ù‡Ø§Ø²",
        "Ù†Ø³ÙŠØ§Ù† Ø§Ù„Ø´Ù‡Ø± Ø£Ùˆ Ø§Ù„Ø³Ù†Ø© Ø§Ù„ØµØ­ÙŠØ­Ø©",
        "ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø´Ø¤ÙˆÙ† Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Ù…Ø«Ù„ Ø¯ÙØ¹ Ø§Ù„ÙÙˆØ§ØªÙŠØ±)",
        "ØµØ¹ÙˆØ¨Ø© ÙÙŠ ØªØ°ÙƒØ± Ø§Ù„Ù…ÙˆØ§Ø¹ÙŠØ¯",
        "ØªØ¯Ù‡ÙˆØ± Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„ÙŠÙˆÙ…ÙŠ"
    ]
}
AD8_OPTS = {"English": ["No", "Yes"], "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": ["Ù„Ø§", "Ù†Ø¹Ù…"]}

# ---------- EEG utilities ----------
BAND_DEFS = {
    "Delta (0.5â€“4 Hz)": (0.5, 4),
    "Theta (4â€“8 Hz)": (4, 8),
    "Alpha (8â€“12 Hz)": (8, 12),
    "Beta (12â€“30 Hz)": (12, 30),
    "Gamma (30â€“45 Hz)": (30, 45)
}

def preprocess_raw_safe(raw):
    """Bandpass + notch + attempt ICA safely"""
    try:
        raw.load_data()
    except Exception:
        pass
    # bandpass
    try:
        raw.filter(0.5, 45.0, fir_design="firwin", verbose=False)
    except Exception:
        pass
    # notch mains 50 & 60
    try:
        raw.notch_filter(freqs=[50.0, 60.0], verbose=False)
    except Exception:
        pass
    ica_applied = False
    try:
        picks = mne.pick_types(raw.info, eeg=True)
        if len(picks) >= 4:
            n_comp = min(15, max(1, len(picks)-1))
            ica = mne.preprocessing.ICA(n_components=n_comp, random_state=42, max_iter="auto")
            ica.fit(raw)
            try:
                eog_inds, scores = ica.find_bads_eog(raw)
                if eog_inds:
                    ica.exclude = eog_inds
            except Exception:
                pass
            try:
                ica.apply(raw)
                ica_applied = True
            except Exception:
                ica_applied = False
    except Exception:
        ica_applied = False
    return raw, {"ica_applied": ica_applied, "n_channels": len(mne.pick_types(raw.info, eeg=True))}

def compute_band_powers(raw):
    try:
        psd = raw.compute_psd(method="welch", fmin=0.5, fmax=45.0, n_fft=2048, n_overlap=1024, verbose=False)
        psds, freqs = psd.get_data(return_freqs=True)
        mean_psd = psds.mean(axis=0) if psds.ndim==2 else psds
    except Exception:
        data = raw.get_data()
        sf = int(raw.info.get("sfreq", 256))
        N = min(4096, data.shape[1])
        freqs = np.fft.rfftfreq(N, 1.0/sf)
        mean_psd = np.abs(np.fft.rfft(data.mean(axis=0)[:N], n=N))
    band_powers = {}
    for name, (lo, hi) in BAND_DEFS.items():
        mask = (freqs >= lo) & (freqs < hi)
        band_powers[name] = float(np.trapz(mean_psd[mask], freqs[mask])) if mask.any() else 0.0
    return band_powers

# ---------- plotting ----------
def plot_band_png(band_powers):
    labels = list(band_powers.keys())
    vals = [band_powers[l] for l in labels]
    fig, ax = plt.subplots(figsize=(7,3), dpi=120)
    ax.bar(labels, vals)
    ax.set_ylabel("Integrated power (a.u.)")
    ax.set_title("EEG Band Powers")
    ax.tick_params(axis="x", rotation=25)
    fig.tight_layout()
    buf = io.BytesIO(); fig.savefig(buf, format="png"); plt.close(fig); buf.seek(0)
    return buf.getvalue()

def plot_signal_png(raw, seconds=8):
    picks = mne.pick_types(raw.info, eeg=True)
    data = raw.get_data(picks=picks) if len(picks)>0 else raw.get_data()
    ch0 = data[0] if data.ndim==2 else data
    sf = int(raw.info.get("sfreq", 256))
    n = min(len(ch0), seconds*sf)
    t = np.arange(n)/sf
    fig, ax = plt.subplots(figsize=(7,2.4), dpi=120)
    ax.plot(t, ch0[:n])
    ax.set_xlabel("Time (s)"); ax.set_ylabel("Amplitude (a.u.)")
    ax.set_title(f"EEG snippet (~{n/sf:.1f}s)")
    fig.tight_layout()
    buf = io.BytesIO(); fig.savefig(buf, format="png"); plt.close(fig); buf.seek(0)
    return buf.getvalue()

# ---------- heuristics ----------
def eeg_heuristics(band_powers):
    alpha = band_powers.get("Alpha (8â€“12 Hz)", 1e-9)
    theta = band_powers.get("Theta (4â€“8 Hz)", 0.0)
    beta = band_powers.get("Beta (12â€“30 Hz)", 0.0)
    theta_alpha = theta/alpha if alpha>0 else 0.0
    beta_alpha = beta/alpha if alpha>0 else 0.0
    return {"Theta/Alpha": round(theta_alpha,3), "Beta/Alpha": round(beta_alpha,3)}

def compute_early_index(band_powers, phq_score, ad8_score, weights=(0.5,0.3,0.2)):
    heur = eeg_heuristics(band_powers)
    ta = min(heur["Theta/Alpha"], 2.0)/2.0
    ba_inv = min(max(1.0 - heur["Beta/Alpha"], 0.0), 1.0)
    eeg_comp = (ta + ba_inv)/2.0
    phq_norm = min(max(phq_score/27.0, 0.0), 1.0)
    ad8_norm = min(max(ad8_score/8.0, 0.0), 1.0)
    idx = weights[0]*eeg_comp + weights[1]*phq_norm + weights[2]*ad8_norm
    return min(max(idx,0.0),1.0), {"eeg_comp": round(eeg_comp,3), "phq_norm": round(phq_norm,3), "ad8_norm": round(ad8_norm,3)}

# ---------- PDF: font + shaping ----------
FONT_DIR = "fonts"
AMIRI_TTF = os.path.join(FONT_DIR, "Amiri-Regular.ttf")
AMIRI_URL = "https://github.com/alif-type/amiri/raw/master/Amiri-Regular.ttf"

def ensure_amiri():
    os.makedirs(FONT_DIR, exist_ok=True)
    if not os.path.exists(AMIRI_TTF):
        try:
            urllib.request.urlretrieve(AMIRI_URL, AMIRI_TTF)
        except Exception:
            return False
    try:
        pdfmetrics.registerFont(TTFont("Amiri", AMIRI_TTF))
        return True
    except Exception:
        return False

def shape_ar(text):
    if not text:
        return ""
    if ARABIC_SUPPORT:
        return get_display(arabic_reshaper.reshape(text))
    return text

def shape_for_pdf(text, lang):
    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        return shape_ar(text)
    return text

def build_pdf_bytes(results, band_png=None, sig_png=None):
    buf = io.BytesIO()
    doc = SimpleDocTemplate(buf, pagesize=A4)
    styles = getSampleStyleSheet()
    flow = []

    # Register font if Arabic content expected
    ensure_amiri()

    # Title EN
    flow.append(Paragraph("NeuroEarly Pro â€” Report", styles["Title"]))
    flow.append(Spacer(1,6))
    flow.append(Paragraph(f"Timestamp: {results.get('timestamp','')}", styles["Normal"]))
    flow.append(Spacer(1,8))

    # EEG table (EN)
    flow.append(Paragraph("EEG Summary", styles["Heading3"]))
    eeg = results.get("EEG",{})
    rows = [["Metric","Value"]]
    rows.append(["File", eeg.get("filename","-")])
    rows.append(["Sampling rate (Hz)", str(eeg.get("sfreq","-"))])
    for k,v in eeg.get("bands",{}).items():
        rows.append([k, f"{v:.6g}"])
    t = Table(rows, colWidths=[200,300])
    t.setStyle(TableStyle([("BACKGROUND",(0,0),(-1,0),colors.lightgrey),("GRID",(0,0),(-1,-1),0.25,colors.grey)]))
    flow.append(t); flow.append(Spacer(1,8))
    if band_png:
        flow.append(RLImage(io.BytesIO(band_png), width=420, height=160)); flow.append(Spacer(1,6))
    if sig_png:
        flow.append(RLImage(io.BytesIO(sig_png), width=420, height=120)); flow.append(Spacer(1,8))

    # PHQ EN
    flow.append(Paragraph("PHQ-9 (Depression) â€” EN", styles["Heading3"]))
    phq = results.get("PHQ9",{})
    flow.append(Paragraph(f"Score: {phq.get('score','-')} â€” {phq.get('label','')}", styles["Normal"]))
    # table answers
    if phq.get("questions"):
        ptab = [["Question","Answer"]]
        for q,a in zip(phq.get("questions"), phq.get("answers")):
            ptab.append([q, str(a)])
        t2 = Table(ptab, colWidths=[320,180]); t2.setStyle(TableStyle([("GRID",(0,0),(-1,-1),0.25,colors.grey)]))
        flow.append(t2)
    flow.append(Spacer(1,8))

    # AD8 EN
    flow.append(Paragraph("AD8 (Cognition) â€” EN", styles["Heading3"]))
    ad8 = results.get("AD8",{})
    flow.append(Paragraph(f"Score: {ad8.get('score','-')} â€” {ad8.get('label','')}", styles["Normal"]))
    if ad8.get("questions"):
        atab = [["Question","Answer"]]
        for q,a in zip(ad8.get("questions"), ad8.get("answers")):
            atab.append([q, "Yes" if a==1 else "No"])
        t3 = Table(atab, colWidths=[320,180]); t3.setStyle(TableStyle([("GRID",(0,0),(-1,-1),0.25,colors.grey)]))
        flow.append(t3)
    flow.append(Spacer(1,12))

    # Early index
    early = results.get("EarlyRisk",{})
    flow.append(Paragraph(f"Early Risk Index: {early.get('index','-')}", styles["Heading3"]))
    flow.append(Paragraph(f"Components: {early.get('components','')}", styles["Normal"]))
    flow.append(Spacer(1,12))

    # Separator then Arabic section
    flow.append(Paragraph("Ù€" * 80, styles["Normal"]))
    flow.append(Spacer(1,6))

    # Arabic: register style using Amiri if available
    arabic_style = styles["Normal"]
    try:
        arabic_style = ParagraphStyle(name="Arabic", fontName="Amiri", fontSize=10, leading=12)
    except Exception:
        arabic_style = styles["Normal"]

    # Title AR
    flow.append(Paragraph(shape_for_pdf("ØªÙ‚Ø±ÙŠØ± Ù†ÙŠÙˆØ±ÙˆØ¥ÙŠØ±Ù„ÙŠ Ø¨Ø±Ùˆ", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    flow.append(Spacer(1,6))
    flow.append(Paragraph(shape_for_pdf(f"Ø§Ù„Ø·Ø§Ø¨Ø¹ Ø§Ù„Ø²Ù…Ù†ÙŠ: {results.get('timestamp','')}", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    flow.append(Spacer(1,8))

    # EEG AR table
    flow.append(Paragraph(shape_for_pdf("Ù…Ù„Ø®Øµ EEG", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    rows_ar = [[shape_for_pdf("Ø§Ù„Ù…Ù‚ÙŠØ§Ø³","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf("Ø§Ù„Ù‚ÙŠÙ…Ø©","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")]]
    rows_ar.append([shape_for_pdf("Ø§Ù„Ù…Ù„Ù","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf(eeg.get("filename","-"), "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")])
    rows_ar.append([shape_for_pdf("Ù…Ø¹Ø¯Ù„ Ø£Ø®Ø° Ø§Ù„Ø¹ÙŠÙ†Ø§Øª (Ù‡Ø±ØªØ²)","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf(str(eeg.get("sfreq","-")),"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")])
    for k,v in eeg.get("bands",{}).items():
        rows_ar.append([shape_for_pdf(k,"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf(f"{v:.6g}","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")])
    t_ar = Table(rows_ar, colWidths=[200,300]); t_ar.setStyle(TableStyle([("BACKGROUND",(0,0),(-1,0),colors.lightgrey),("GRID",(0,0),(-1,-1),0.25,colors.grey)]))
    flow.append(t_ar); flow.append(Spacer(1,8))

    # images (reuse)
    if band_png:
        flow.append(RLImage(io.BytesIO(band_png), width=420, height=160)); flow.append(Spacer(1,6))
    if sig_png:
        flow.append(RLImage(io.BytesIO(sig_png), width=420, height=120)); flow.append(Spacer(1,8))

    # PHQ AR
    flow.append(Paragraph(shape_for_pdf("PHQ-9 (Ø§Ù„Ø§ÙƒØªØ¦Ø§Ø¨)", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    flow.append(Paragraph(shape_for_pdf(f"Ø§Ù„Ø¯Ø±Ø¬Ø©: {phq.get('score','-')} â€” {phq.get('label','')}", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    if phq.get("questions"):
        ptab_ar = [[shape_for_pdf("Ø§Ù„Ø³Ø¤Ø§Ù„","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")]]
        for q,a in zip(phq.get("questions_ar", phq.get("questions")), phq.get("answers")):
            ptab_ar.append([shape_for_pdf(q,"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf(str(a),"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")])
        t2_ar = Table(ptab_ar, colWidths=[320,180]); t2_ar.setStyle(TableStyle([("GRID",(0,0),(-1,-1),0.25,colors.grey)]))
        flow.append(t2_ar)
    flow.append(Spacer(1,8))

    # AD8 AR
    flow.append(Paragraph(shape_for_pdf("AD8 (Ø§Ù„Ù…Ø¹Ø±ÙÙŠ)", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    flow.append(Paragraph(shape_for_pdf(f"Ø§Ù„Ø¯Ø±Ø¬Ø©: {ad8.get('score','-')} â€” {ad8.get('label','')}", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))
    if ad8.get("questions_ar"):
        atab_ar = [[shape_for_pdf("Ø§Ù„Ø³Ø¤Ø§Ù„","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf("Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")]]
        for q,a in zip(ad8.get("questions_ar"), ad8.get("answers")):
            atab_ar.append([shape_for_pdf(q,"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), shape_for_pdf("Ù†Ø¹Ù…" if a==1 else "Ù„Ø§","Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©")])
        t3_ar = Table(atab_ar, colWidths=[320,180]); t3_ar.setStyle(TableStyle([("GRID",(0,0),(-1,-1),0.25,colors.grey)]))
        flow.append(t3_ar)

    # final note
    flow.append(Spacer(1,10))
    note_en = "This report is a research demo. Elevated theta/alpha may relate to depressive patterns; low beta/alpha may suggest cognitive concerns. Results are preliminary and require clinical follow-up."
    note_ar = "Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ø­Ø«ÙŠ. Ù‚Ø¯ ÙŠØ±ØªØ¨Ø· Ø§Ø±ØªÙØ§Ø¹ Ù†Ø³Ø¨Ø© theta/alpha Ø¨Ø£Ù†Ù…Ø§Ø· Ø§ÙƒØªØ¦Ø§Ø¨ÙŠØ©Ø› Ù‚Ø¯ ÙŠØ´ÙŠØ± Ø§Ù†Ø®ÙØ§Ø¶ beta/alpha Ø¥Ù„Ù‰ Ù…Ø®Ø§ÙˆÙ Ø¥Ø¯Ø±Ø§ÙƒÙŠØ©. Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø£ÙˆÙ„ÙŠØ© ÙˆÙŠØ¬Ø¨ Ù…ØªØ§Ø¨Ø¹ØªÙ‡Ø§ Ø³Ø±ÙŠØ±ÙŠÙ‹Ø§."
    flow.append(Paragraph(note_en, styles["Italic"]))
    flow.append(Spacer(1,6))
    flow.append(Paragraph(shape_for_pdf(note_ar,"Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"), arabic_style))

    doc.build(flow)
    buf.seek(0)
    return buf.getvalue()

# ---------- UI: Upload ----------
st.header(TUI["upload"])
st.write(TUI["upload_hint"])
uploaded_files = st.file_uploader("Select EDF file(s)", type=["edf"], accept_multiple_files=True)

session_list = []
if uploaded_files:
    st.info(f"{len(uploaded_files)} file(s) selected.")
    for f in uploaded_files:
        with st.spinner(f"Processing {f.name} ..."):
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".edf") as tmp:
                    tmp.write(f.read()); tmp_path = tmp.name
                raw = mne.io.read_raw_edf(tmp_path, preload=True, verbose=False)
                raw_clean, meta = preprocess_raw_safe(raw)
                bands = compute_band_powers(raw_clean)
                heur = eeg_heuristics(bands)
                sig_png = plot_signal_png(raw_clean, seconds=8)
                band_png = plot_band_png(bands)
                session_list.append({
                    "filename": f.name,
                    "sfreq": float(raw.info.get("sfreq", math.nan)),
                    "bands": bands,
                    "heuristics": heur,
                    "meta": meta,
                    "sig_png": sig_png,
                    "band_png": band_png
                })
                st.success(f"{f.name} processed â€” channels: {meta.get('n_channels',0)}, ICA applied: {meta.get('ica_applied',False)}")
                st.image(band_png, use_column_width=True)
            except Exception as e:
                st.error(f"Failed to process {f.name}: {e}")

# ---------- UI: PHQ-9 ----------
st.header(TUI["phq"])
phq_lang = "English" if IS_EN else "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
phq_questions = PHQ_QS[phq_lang]
phq_opts = PHQ_OPTS[phq_lang]
special_q8_opts = SPECIAL_Q8[phq_lang]

phq_answers = []
for i, q in enumerate(phq_questions, start=1):
    if i == 8:
        ans = st.selectbox(f"{i}. {q}", special_q8_opts, key=f"phq_{i}")
        # numeric prefix: "0 = ..." or in Arabic "0 = ..." -> parse left side until first space or '='
        try:
            val = int(ans.split("=")[0].strip())
        except Exception:
            val = 0
        phq_answers.append(val)
    else:
        ans = st.selectbox(f"{i}. {q}", phq_opts, key=f"phq_{i}")
        try:
            val = int(ans.split("=")[0].strip())
        except Exception:
            val = 0
        phq_answers.append(val)

# appetite type stored separately
if IS_EN:
    appetite_type = st.radio("If appetite change: which?", ["Poor appetite", "Overeating"], key="q5_type")
else:
    appetite_type = st.radio("Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØºÙŠØ± ÙÙŠ Ø§Ù„Ø´Ù‡ÙŠØ©: Ù…Ø§ Ù†ÙˆØ¹Ù‡ØŸ", ["ÙÙ‚Ø¯Ø§Ù† Ø§Ù„Ø´Ù‡ÙŠØ©", "Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„Ø£ÙƒÙ„"], key="q5_type")

phq_score = sum(phq_answers)
if phq_score < 5:
    phq_label = "Minimal" if IS_EN else "Ø·ÙÙŠÙ"
elif phq_score < 10:
    phq_label = "Mild" if IS_EN else "Ø®ÙÙŠÙ"
elif phq_score < 15:
    phq_label = "Moderate" if IS_EN else "Ù…ØªÙˆØ³Ø·"
elif phq_score < 20:
    phq_label = "Moderately severe" if IS_EN else "Ø´Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ø­Ø¯ Ù…Ø§"
else:
    phq_label = "Severe" if IS_EN else "Ø´Ø¯ÙŠØ¯"

st.write((f"PHQ-9: {phq_score} / 27 â€” {phq_label}") if IS_EN else (f"Ø¯Ø±Ø¬Ø© PHQ-9: {phq_score} / Ù¢Ù§ â€” {phq_label}"))

# ---------- UI: AD8 ----------
st.header(TUI["ad8"])
ad8_lang = "English" if IS_EN else "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
ad8_questions = AD8_QS[ad8_lang]
ad8_opts = AD8_OPTS[ad8_lang]
ad8_answers = []
for i, q in enumerate(ad8_questions, start=1):
    ans = st.selectbox(f"{i}. {q}", ad8_opts, key=f"ad8_{i}")
    ad8_answers.append(1 if ans == ( "Yes" if IS_EN else "Ù†Ø¹Ù…") else 0)
ad8_score = sum(ad8_answers)
ad8_label = ("Possible concern (â‰¥2)" if ad8_score>=2 else "Low") if IS_EN else ("Ø§Ø­ØªÙ…Ø§Ù„ Ù‚Ù„Ù‚ (â‰¥Ù¢)" if ad8_score>=2 else "Ù…Ù†Ø®ÙØ¶")
st.write((f"AD8: {ad8_score} / 8 â€” {ad8_label}") if IS_EN else (f"Ø¯Ø±Ø¬Ø© AD8: {ad8_score} / Ù¨ â€” {ad8_label}"))

# ---------- Generate reports ----------
st.header(TUI["generate"])
if st.button("Generate Reports (JSON / CSV / PDF)"):
    sessions_meta = []
    for s in session_list:
        sessions_meta.append({
            "filename": s["filename"],
            "sfreq": s["sfreq"],
            "bands": s["bands"],
            "heuristics": s["heuristics"],
            "ica_applied": s["meta"].get("ica_applied", False)
        })
    last_bands = session_list[-1]["bands"] if session_list else {k:0.0 for k in BAND_DEFS.keys()}
    early_idx, early_comp = compute_early_index(last_bands, phq_score, ad8_score)

    results = {
        "timestamp": datetime.now().isoformat(),
        "language_ui": LANG_UI,
        "PHQ9": {
            "score": phq_score,
            "label": phq_label,
            "answers": phq_answers,
            "questions": PHQ_QS["English"],
            "questions_ar": PHQ_QS["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"],
            "appetite_type": appetite_type
        },
        "AD8": {
            "score": ad8_score,
            "label": ad8_label,
            "answers": ad8_answers,
            "questions": AD8_QS["English"],
            "questions_ar": AD8_QS["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"]
        },
        "EarlyRisk": {"index": round(early_idx,3), "components": early_comp},
        "sessions": sessions_meta,
        "note": TUI.get("note","")
    }

    # JSON
    json_bytes = io.BytesIO(json.dumps(results, indent=2, ensure_ascii=False).encode("utf-8"))
    st.download_button("â¬‡ï¸ Download JSON", data=json_bytes, file_name="neuroearly_report.json", mime="application/json")

    # CSV (features)
    if sessions_meta:
        df_rows = []
        for s in sessions_meta:
            r = {"filename": s["filename"], "sfreq": s["sfreq"]}
            r.update(s["bands"])
            r.update(s["heuristics"])
            df_rows.append(r)
        df = pd.DataFrame(df_rows)
        csv_buf = io.StringIO(); df.to_csv(csv_buf, index=False)
        st.download_button("â¬‡ï¸ Download CSV (features)", data=csv_buf.getvalue(), file_name="neuroearly_features.csv", mime="text/csv")

    # PDF (bilingual)
    band_png = session_list[-1]["band_png"] if session_list else None
    sig_png = session_list[-1]["sig_png"] if session_list else None
    pdf_bytes = build_pdf_bytes(results, band_png=band_png, sig_png=sig_png)
    st.download_button("â¬‡ï¸ Download PDF (bilingual)", data=pdf_bytes, file_name="neuroearly_bilingual_report.pdf", mime="application/pdf")

st.caption(TUI.get("note",""))
